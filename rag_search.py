# """
# Module de recherche RAG pour le chatbot ADES
# Permet de rechercher dans la documentation et rÃ©cupÃ©rer le contexte pertinent
# """

# from sentence_transformers import SentenceTransformer
# import faiss
# import pickle
# import os

# class RAGSearcher:
#     """
#     Classe pour gÃ©rer la recherche sÃ©mantique dans la documentation ADES
#     """
    
#     def __init__(self, data_dir='rag/data', model_name='all-MiniLM-L6-v2'):
#         """
#         Initialise le RAG Searcher
        
#         Args:
#             data_dir: Dossier contenant les fichiers FAISS et chunks
#             model_name: Nom du modÃ¨le d'embeddings
#         """
#         self.data_dir = data_dir
#         self.model_name = model_name
        
#         self.model = None
#         self.index = None
#         self.chunks = None
#         self.metadata = None
        
#         print(f"ğŸ” Initialisation du RAG Searcher...")
#         self._load_resources()
    
#     def _load_resources(self):
#         """
#         Charge le modÃ¨le, l'index FAISS et les chunks
#         """
#         try:
#             # Chemins des fichiers
#             index_path = os.path.join(self.data_dir, 'faiss_index.index')
#             chunks_path = os.path.join(self.data_dir, 'chunks.pkl')
#             metadata_path = os.path.join(self.data_dir, 'metadata.pkl')
            
#             # VÃ©rifier que les fichiers existent
#             if not os.path.exists(index_path):
#                 raise FileNotFoundError(f"Index FAISS introuvable : {index_path}")
#             if not os.path.exists(chunks_path):
#                 raise FileNotFoundError(f"Chunks introuvables : {chunks_path}")
            
#             # Charger le modÃ¨le d'embeddings
#             print(f"  ğŸ“¦ Chargement du modÃ¨le : {self.model_name}")
#             self.model = SentenceTransformer(self.model_name)
            
#             # Charger l'index FAISS
#             print(f"  ğŸ—„ï¸  Chargement de l'index FAISS...")
#             self.index = faiss.read_index(index_path)
            
#             # Charger les chunks
#             print(f"  ğŸ“„ Chargement des chunks...")
#             with open(chunks_path, 'rb') as f:
#                 self.chunks = pickle.load(f)
            
#             # Charger les mÃ©tadonnÃ©es (optionnel)
#             if os.path.exists(metadata_path):
#                 with open(metadata_path, 'rb') as f:
#                     self.metadata = pickle.load(f)
            
#             print(f"âœ… RAG Searcher prÃªt !")
#             print(f"   - {len(self.chunks)} chunks chargÃ©s")
#             print(f"   - Dimension des vecteurs : {self.index.d}")
            
#         except Exception as e:
#             print(f"âŒ Erreur lors du chargement des ressources : {e}")
#             raise
    
#     def search(self, query, top_k=3, return_scores=False):
#         """
#         Recherche les chunks les plus pertinents pour une question
        
#         Args:
#             query: Question de l'utilisateur
#             top_k: Nombre de rÃ©sultats Ã  retourner
#             return_scores: Si True, retourne aussi les scores
            
#         Returns:
#             Liste des chunks pertinents (et scores si demandÃ©)
#         """
#         try:
#             # Encoder la question
#             query_embedding = self.model.encode([query])
            
#             # Rechercher dans FAISS
#             distances, indices = self.index.search(
#                 query_embedding.astype('float32'), 
#                 top_k
#             )
            
#             # RÃ©cupÃ©rer les chunks correspondants
#             results = []
#             for dist, idx in zip(distances[0], indices[0]):
#                 chunk = self.chunks[idx]
                
#                 if return_scores:
#                     results.append({
#                         'chunk': chunk,
#                         'score': float(dist),
#                         'index': int(idx)
#                     })
#                 else:
#                     results.append(chunk)
            
#             return results
            
#         except Exception as e:
#             print(f"âŒ Erreur lors de la recherche : {e}")
#             return []
    
#     def get_context(self, query, top_k=3, max_length=2000):
#         """
#         RÃ©cupÃ¨re le contexte pertinent pour une question
#         Formate le contexte pour Ãªtre injectÃ© dans le prompt
        
#         Args:
#             query: Question de l'utilisateur
#             top_k: Nombre de chunks Ã  rÃ©cupÃ©rer
#             max_length: Longueur maximale du contexte (en caractÃ¨res)
            
#         Returns:
#             Contexte formatÃ© (string)
#         """
#         # Rechercher les chunks pertinents
#         chunks = self.search(query, top_k=top_k)
        
#         # ConcatÃ©ner les chunks
#         context = "\n\n".join(chunks)
        
#         # Limiter la longueur si nÃ©cessaire
#         if len(context) > max_length:
#             context = context[:max_length] + "\n\n[...]"
        
#         return context
    
#     def get_detailed_results(self, query, top_k=3):
#         """
#         Retourne des rÃ©sultats dÃ©taillÃ©s avec scores et mÃ©tadonnÃ©es
#         Utile pour dÃ©boguer et analyser
        
#         Args:
#             query: Question de l'utilisateur
#             top_k: Nombre de rÃ©sultats
            
#         Returns:
#             Liste de dictionnaires avec dÃ©tails
#         """
#         results = self.search(query, top_k=top_k, return_scores=True)
        
#         detailed = []
#         for result in results:
#             detailed.append({
#                 'chunk': result['chunk'],
#                 'score': result['score'],
#                 'index': result['index'],
#                 'preview': result['chunk'][:200] + "..." if len(result['chunk']) > 200 else result['chunk']
#             })
        
#         return detailed
    
#     def health_check(self):
#         """
#         VÃ©rifie que le RAG est fonctionnel
        
#         Returns:
#             dict avec le statut
#         """
#         try:
#             if self.model is None or self.index is None or self.chunks is None:
#                 return {
#                     'status': 'error',
#                     'message': 'Ressources non chargÃ©es'
#                 }
            
#             # Test rapide de recherche
#             test_results = self.search("test", top_k=1)
            
#             return {
#                 'status': 'ok',
#                 'num_chunks': len(self.chunks),
#                 'embedding_dim': self.index.d,
#                 'model': self.model_name,
#                 'test_search': 'ok' if test_results else 'failed'
#             }
            
#         except Exception as e:
#             return {
#                 'status': 'error',
#                 'message': str(e)
#             }


# # ============== TEST ==============

# if __name__ == "__main__":
#     """
#     Test du module
#     """
#     print("=" * 60)
#     print("TEST DU MODULE RAG SEARCH")
#     print("=" * 60)
    
#     # Initialiser
#     searcher = RAGSearcher()
    
#     # Test 1 : Recherche simple
#     print("\nğŸ“ Test 1 : Recherche simple")
#     query = "Comment crÃ©er une vente?"
#     results = searcher.search(query, top_k=2)
#     print(f"\nQuestion : {query}")
#     for i, chunk in enumerate(results):
#         print(f"\nRÃ©sultat {i+1}:")
#         print(chunk[:200] + "...")
    
#     # Test 2 : Get context
#     print("\nğŸ“ Test 2 : Get context")
#     context = searcher.get_context(query, top_k=2)
#     print(f"\nContexte rÃ©cupÃ©rÃ© ({len(context)} caractÃ¨res):")
#     print(context[:300] + "...")
    
#     # Test 3 : RÃ©sultats dÃ©taillÃ©s
#     print("\nğŸ“ Test 3 : RÃ©sultats dÃ©taillÃ©s")
#     detailed = searcher.get_detailed_results(query, top_k=2)
#     for i, result in enumerate(detailed):
#         print(f"\nRÃ©sultat {i+1}:")
#         print(f"  Score: {result['score']:.4f}")
#         print(f"  Preview: {result['preview']}")
    
#     # Test 4 : Health check
#     print("\nğŸ“ Test 4 : Health check")
#     health = searcher.health_check()
#     print(f"\nStatut: {health}")
    
#     print("\n" + "=" * 60)
#     print("âœ… TESTS TERMINÃ‰S")
#     print("=" * 60)

"""
Module de recherche RAG pour le chatbot ADES
Permet de rechercher dans la documentation et rÃ©cupÃ©rer le contexte pertinent
"""

from sentence_transformers import SentenceTransformer
import faiss
import pickle
import os

class RAGSearcher:
    """
    Classe pour gÃ©rer la recherche sÃ©mantique dans la documentation ADES
    """
    
    def __init__(self, data_dir='rag/data', model_name='all-MiniLM-L6-v2'):
        """
        Initialise le RAG Searcher
        
        Args:
            data_dir: Dossier contenant les fichiers FAISS et chunks
            model_name: Nom du modÃ¨le d'embeddings
        """
        self.data_dir = data_dir
        self.model_name = model_name
        
        self.model = None
        self.index = None
        self.chunks = None
        self.metadata = None
        
        print(f"ğŸ” Initialisation du RAG Searcher...")
        self._load_resources()
    
    def _load_resources(self):
        """
        Charge le modÃ¨le, l'index FAISS et les chunks
        """
        try:
            # Chemins des fichiers
            index_path = os.path.join(self.data_dir, 'faiss_index.index')
            chunks_path = os.path.join(self.data_dir, 'chunks.pkl')
            metadata_path = os.path.join(self.data_dir, 'metadata.pkl')
            
            # VÃ©rifier que les fichiers existent
            if not os.path.exists(index_path):
                raise FileNotFoundError(f"Index FAISS introuvable : {index_path}")
            if not os.path.exists(chunks_path):
                raise FileNotFoundError(f"Chunks introuvables : {chunks_path}")
            
            # Charger le modÃ¨le d'embeddings
            print(f"   ğŸ“¦ Chargement du modÃ¨le : {self.model_name}")
            self.model = SentenceTransformer(self.model_name)
            
            # Charger l'index FAISS
            print(f"   ğŸ—„ï¸  Chargement de l'index FAISS...")
            self.index = faiss.read_index(index_path)
            
            # Charger les chunks
            print(f"   ğŸ“„ Chargement des chunks...")
            with open(chunks_path, 'rb') as f:
                self.chunks = pickle.load(f)
            
            # Charger les mÃ©tadonnÃ©es (optionnel)
            if os.path.exists(metadata_path):
                with open(metadata_path, 'rb') as f:
                    self.metadata = pickle.load(f)
            
            print(f"âœ… RAG Searcher prÃªt !")
            print(f"   - {len(self.chunks)} chunks chargÃ©s")
            print(f"   - Dimension des vecteurs : {self.index.d}")
            
        except Exception as e:
            print(f"âŒ Erreur lors du chargement des ressources : {e}")
            raise
    
    def _extract_text_from_chunk(self, chunk):
        """
        Logique interne pour extraire le texte d'une structure de chunk.
        """
        if isinstance(chunk, str):
            return chunk
        elif isinstance(chunk, dict):
            # Tente d'extraire de la clÃ© 'chunk' (ou 'text' si c'est une autre convention)
            return chunk.get('chunk') or chunk.get('text')
        elif isinstance(chunk, (list, tuple)) and len(chunk) > 0:
            # Tente d'extraire du premier Ã©lÃ©ment (souvent le texte)
            return self._extract_text_from_chunk(chunk[0])
        return None
    
    def search(self, query, top_k=3, return_scores=False):
        """
        Recherche les chunks les plus pertinents pour une question
        
        Args:
            query: Question de l'utilisateur
            top_k: Nombre de rÃ©sultats Ã  retourner
            return_scores: Si True, retourne aussi les scores
            
        Returns:
            Liste des chunks pertinents (strings si return_scores=False, dicts sinon)
        """
        try:
            # Encoder la question
            query_embedding = self.model.encode([query])
            
            # Rechercher dans FAISS
            distances, indices = self.index.search(
                query_embedding.astype('float32'), 
                top_k
            )
            
            # RÃ©cupÃ©rer les chunks correspondants
            results = []
            for dist, idx in zip(distances[0], indices[0]):
                chunk = self.chunks[idx]
                
                if return_scores:
                    # Retourne le chunk brut dans le dictionnaire de rÃ©sultats
                    results.append({
                        'chunk': chunk,
                        'score': float(dist),
                        'index': int(idx)
                    })
                else:
                    # Extrait le texte pour le retour simple
                    extracted_text = self._extract_text_from_chunk(chunk)
                    if extracted_text and extracted_text.strip():
                        results.append(extracted_text)
                    # Note : L'avertissement de type est maintenant dans get_context si nÃ©cessaire.
            
            return results
            
        except Exception as e:
            print(f"âŒ Erreur lors de la recherche : {e}")
            return []
    
    def get_context(self, query, top_k=3, max_length=2000):
        """
        RÃ©cupÃ¨re le contexte pertinent pour une question
        Formate le contexte pour Ãªtre injectÃ© dans le prompt
        
        Args:
            query: Question de l'utilisateur
            top_k: Nombre de chunks Ã  rÃ©cupÃ©rer
            max_length: Longueur maximale du contexte (en caractÃ¨res)
            
        Returns:
            Contexte formatÃ© (string)
        """
        # Rechercher les chunks pertinents. search() retourne maintenant des chaÃ®nes de caractÃ¨res nettoyÃ©es
        # si elles ont pu Ãªtre extraites.
        chunks = self.search(query, top_k=top_k)
        
        # Le filtrage des types inattendus a Ã©tÃ© dÃ©placÃ© dans _extract_text_from_chunk
        # pour uniformiser le process de search. Cependant, s'il reste des Ã©lÃ©ments
        # non-textuels, ils doivent Ãªtre filtrÃ©s ici pour le join.
        
        text_chunks = []
        for chunk in chunks:
            if isinstance(chunk, str) and chunk.strip():
                text_chunks.append(chunk)
            else:
                 # Ce cas ne devrait plus arriver si search() est correctement implÃ©mentÃ©, 
                 # mais nous le conservons pour la robustesse future.
                 print(f"âŒ Avertissement RAG: Ã‰lÃ©ment de chunk non-texte ignorÃ© lors du formatage. Type: {type(chunk)}")


        # ConcatÃ©ner les chunks
        context = "\n\n".join(text_chunks)
        
        # Limiter la longueur si nÃ©cessaire
        if len(context) > max_length:
            context = context[:max_length] + "\n\n[...]"
        
        return context
    
    def get_detailed_results(self, query, top_k=3):
        """
        Retourne des rÃ©sultats dÃ©taillÃ©s avec scores et mÃ©tadonnÃ©es
        Utile pour dÃ©boguer et analyser
        
        Args:
            query: Question de l'utilisateur
            top_k: Nombre de rÃ©sultats
            
        Returns:
            Liste de dictionnaires avec dÃ©tails
        """
        # On utilise search avec return_scores=True pour obtenir les dictionnaires bruts
        results = self.search(query, top_k=top_k, return_scores=True)
        
        detailed = []
        for result in results:
            # Utiliser la nouvelle mÃ©thode d'extraction pour assurer que l'aperÃ§u est lisible
            chunk_content = self._extract_text_from_chunk(result['chunk'])
            
            detailed.append({
                'chunk': chunk_content if chunk_content else "Contenu non extractible",
                'score': result['score'],
                'index': result['index'],
                'preview': (chunk_content[:200] + "...") if chunk_content and len(chunk_content) > 200 else (chunk_content or "Contenu non extractible")
            })
        
        return detailed
    
    def health_check(self):
        """
        VÃ©rifie que le RAG est fonctionnel
        
        Returns:
            dict avec le statut
        """
        try:
            if self.model is None or self.index is None or self.chunks is None:
                return {
                    'status': 'error',
                    'message': 'Ressources non chargÃ©es'
                }
            
            # Test rapide de recherche
            test_results = self.search("test", top_k=1)
            
            return {
                'status': 'ok',
                'num_chunks': len(self.chunks),
                'embedding_dim': self.index.d,
                'model': self.model_name,
                'test_search': 'ok' if test_results else 'failed'
            }
            
        except Exception as e:
            return {
                'status': 'error',
                'message': str(e)
            }


# ============== TEST ==============

if __name__ == "__main__":
    """
    Test du module
    """
    print("=" * 60)
    print("TEST DU MODULE RAG SEARCH")
    print("=" * 60)
    
    # Initialiser
    searcher = RAGSearcher()
    
    # Test 1 : Recherche simple
    print("\nğŸ“ Test 1 : Recherche simple")
    query = "Comment crÃ©er une vente?"
    results = searcher.search(query, top_k=2)
    print(f"\nQuestion : {query}")
    for i, chunk in enumerate(results):
        print(f"\nRÃ©sultat {i+1}:")
        # On vÃ©rifie si c'est une chaÃ®ne avant d'accÃ©der au contenu
        preview = chunk[:200] + "..." if isinstance(chunk, str) and len(chunk) > 200 else str(chunk) 
        print(preview)
    
    # Test 2 : Get context
    print("\nğŸ“ Test 2 : Get context")
    context = searcher.get_context(query, top_k=2)
    print(f"\nContexte rÃ©cupÃ©rÃ© ({len(context)} caractÃ¨res):")
    print(context[:300] + "...")
    
    # Test 3 : RÃ©sultats dÃ©taillÃ©s
    print("\nğŸ“ Test 3 : RÃ©sultats dÃ©taillÃ©s")
    detailed = searcher.get_detailed_results(query, top_k=2)
    for i, result in enumerate(detailed):
        print(f"\nRÃ©sultat {i+1}:")
        print(f"   Score: {result['score']:.4f}")
        print(f"   Preview: {result['preview']}")
    
    # Test 4 : Health check
    print("\nğŸ“ Test 4 : Health check")
    health = searcher.health_check()
    print(f"\nStatut: {health}")
    
    print("\n" + "=" * 60)
    print("âœ… TESTS TERMINÃ‰S")
    print("=" * 60)